{"metadata":{"colab":{"collapsed_sections":[],"include_colab_link":true,"name":"W3D4_Tutorial1","provenance":[],"toc_visible":true},"kernel":{"display_name":"Python 3","language":"python","name":"python3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc-autonumbering":true,"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>","metadata":{"colab_type":"text","execution":{},"id":"view-in-github"}},{"cell_type":"markdown","source":"# Tutorial 1: Basic Reinforcement Learning\n\n**Week 3, Day 4: Basic Reinforcement Learning**\n\n**By Neuromatch Academy**\n\n__Content creators:__ Pablo Samuel Castro\n\n__Content reviewers:__ Shaonan Wang, Xiaomei Mi, Julia Costacurta, Dora Zhiyu Yang, Adrita Das\n\n__Content editors:__ Shaonan Wang\n\n__Production editors:__ Spiros Chavlis","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n# Tutorial Objectives\n\nReinforcement Learning (RL) is a powerful framework for defining and solving problems where an agent learns to take actions that maximize its reward. Essentially, an agent observes the current state of the world, selects an action, receives a reward, and uses this feedback to improve its future actions. RL provides a formal, optimal way of describing this learning process, which was initially derived from studies of animal behavior and later validated by observations of the brain in humans and animals.\n\nThis tutorial will introduce you to the basic concepts of RL using a simple example. By the end, you'll have a better understanding of how RL works and how it can be applied to solve a wide range of problems.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Tutorial slides\nfrom IPython.display import IFrame\nlink_id = \"ztgws\"\nprint(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\nIFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:17.365312Z","iopub.execute_input":"2024-07-30T22:32:17.365741Z","iopub.status.idle":"2024-07-30T22:32:17.414556Z","shell.execute_reply.started":"2024-07-30T22:32:17.365705Z","shell.execute_reply":"2024-07-30T22:32:17.413471Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"If you want to download the slides: https://osf.io/download/ztgws/\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.IFrame at 0x7ae7597ec5e0>","text/html":"\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/ztgws/?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Setup\n\nThis is a GPU free notebook!","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Install and import feedback gadget\n\n!pip3 install vibecheck datatops --quiet\n\nfrom vibecheck import DatatopsContentReviewContainer\ndef content_review(notebook_section: str):\n    return DatatopsContentReviewContainer(\n        \"\",  # No text prompt\n        notebook_section,\n        {\n            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n            \"name\": \"neuromatch_dl\",\n            \"user_key\": \"f379rz8y\",\n        },\n    ).render()\n\n\nfeedback_prefix = \"W3D4_T1\"","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:17.416831Z","iopub.execute_input":"2024-07-30T22:32:17.417166Z","iopub.status.idle":"2024-07-30T22:32:42.394924Z","shell.execute_reply.started":"2024-07-30T22:32:17.417136Z","shell.execute_reply":"2024-07-30T22:32:42.393619Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom typing import Optional, Tuple","metadata":{"cellView":"both","execution":{"iopub.status.busy":"2024-07-30T22:32:42.396671Z","iopub.execute_input":"2024-07-30T22:32:42.397167Z","iopub.status.idle":"2024-07-30T22:32:42.403343Z","shell.execute_reply.started":"2024-07-30T22:32:42.397116Z","shell.execute_reply":"2024-07-30T22:32:42.401801Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"---\n# Section 1: A history of RL\n\nIn this section, we will briefly overview the history of reinforcement learning (RL) in reverse chronological order. This will help motivate why RL is an interesting topic to study!","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 1: Intro to RL\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'x-NyX8bRsTQ'), ('Bilibili', 'BV1wk4y1M7ae')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:42.406065Z","iopub.execute_input":"2024-07-30T22:32:42.406436Z","iopub.status.idle":"2024-07-30T22:32:42.498087Z","shell.execute_reply.started":"2024-07-30T22:32:42.406399Z","shell.execute_reply":"2024-07-30T22:32:42.496904Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7f4b663dd54f6d980feb8268457443"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Intro_to_RL_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:42.503476Z","iopub.execute_input":"2024-07-30T22:32:42.503847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Section 2: What is RL\n\nUsing a very simple problem, we will give a high-level overview of what RL is and what are the main components that define the problem formulation.\n\n**Extra:** If you'd like to read more, the canonical reference for RL is Sutton & Barto's [Reinforcement Learning book](http://incompleteideas.net/book/the-book-2nd.html).","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## Section 2.1: Grid World\n\nGridWorlds are very simple \"navigation\" problems that can be very useful for motivating RL problems and solutions. They are commonly used in RL research, so it's a good idea to get familiar with them!\n\nWe will use a simple GridWorld problem throughout this tutorial: an empty room with a reward at one corner.\n\nAn example below defines a second GridWorld that is a little more difficult. Feel free to create your own!\n\n**Extra:** If you'd like to play with RL in GridWorlds on the web, you can check out this [GridWorld playground web app](https://gridworld-playground.glitch.me/).","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 2: Grid World\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', '4r400A5GNfE'), ('Bilibili', 'BV1GV411M7hk')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Grid_world_Video\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Coding Exercise 1: Code a shortest-path planner for GridWorld\n","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Create the GridWorldPlanner object (defaults to simple example)\n\nASCII_TO_EMOJI = {\n    ' ': '⬜',\n    '*': '⬛',\n    'g': '⭐',\n    '<': '◀️',\n    '>': '▶️',\n    'v': '🔽',\n    '^': '🔼',\n}\n\nACTIONS = ['<', '>', 'v', '^']\nACTION_EFFECTS = {  # Position effects of each action.\n    '<': (0, -1),\n    '>': (0, 1),\n    'v': (1, 0),\n    '^': (-1, 0),\n}\n\n\ndef get_emoji(c, policy=None):\n  assert c in ASCII_TO_EMOJI\n  if policy is not None and c != 'g':\n    assert policy in ASCII_TO_EMOJI\n    if policy != ' ':  # If there is a policy, use this instead.\n      c = policy\n  return ASCII_TO_EMOJI[c]\n\n\nclass GridWorldBase(object):\n  \"\"\"Defines a GridWorldPlanner object.\"\"\"\n\n  def __init__(self, world_spec: Optional[np.ndarray] = None):\n    \"\"\"Creates a GridWorld object with an empty policy.\n\n    Args:\n      world_spec: Optional array specification of GridWorld. If None, will\n                  use default square room.\n    \"\"\"\n    if world_spec is None:\n      self.world_spec = np.array(\n          [['*', '*', '*', '*', '*', '*'],\n           ['*', ' ', ' ', ' ', ' ', '*'],\n           ['*', ' ', ' ', ' ', ' ', '*'],\n           ['*', ' ', ' ', ' ', ' ', '*'],\n           ['*', ' ', ' ', ' ', 'g', '*'],\n           ['*', '*', '*', '*', '*', '*']]\n      )\n    else:\n      assert len(world_spec.shape) == 2\n      self.world_spec = world_spec\n\n    assert len(np.where(self.world_spec == 'g')[0]) == 1  # Only one goal.\n    self.policy = np.full_like(self.world_spec, ' ')\n    # **Note**: These may be useful for your planner!\n    self.goal_cell = [x[0] for x in np.where(self.world_spec == 'g')]\n\n  def get_neighbours(self, cell: Tuple[int, int]):\n    \"\"\"Get the neighbours of a cell.\n\n    **Note**: You should use this when writing your planner!\n\n    Args:\n      cell: cell position.\n\n    Returns:\n      Dict containing neighbouring cells for each of the 4 possible directions.\n    \"\"\"\n    height, width = self.world_spec.shape\n    i, j = cell\n    if i < 1 or i >= height or j < 1 or j >= width:\n      raise ValueError(f'Invalid cell position: {cell}')\n    neighbours = {}\n    for a in ACTIONS:\n      delta = ACTION_EFFECTS[a]\n      neighbour_pos = [i + delta[0], j + delta[1]]\n      if (neighbour_pos[0] < 0 or neighbour_pos[1] < 0 or\n          neighbour_pos[0] >= height or neighbour_pos[1] >= width or\n          self.world_spec[neighbour_pos[0], neighbour_pos[1]] == '*'):\n        # Remain in same cell\n        neighbours[a] = cell\n      else:\n        neighbours[a] = neighbour_pos\n    return neighbours\n\n  def plan(self):\n    \"\"\"Constructs a random policy.\n\n    **Note**: you will make something better further down!\n    \"\"\"\n    for i in range(self.policy.shape[0]):\n      for j in range(self.policy.shape[1]):\n        if self.world_spec[i, j] == '*':  # Nothing to do for walls.\n          continue\n        self.policy[i, j] = ACTIONS[np.random.choice(len(ACTIONS))]\n\n  def draw(self, include_policy: bool = False):\n    \"\"\"Draw the grid, and (optionally) include the policy.\"\"\"\n    for i in range(len(self.world_spec)):\n      row_range = range(len(self.world_spec[i]))\n      if include_policy:\n        row_chars = [get_emoji(self.world_spec[i, j], self.policy[i, j]) for j in row_range]\n      else:\n        row_chars = [get_emoji(self.world_spec[i, j], None) for j in row_range]\n      print(''.join(row_chars))\n\n\ngwb = GridWorldBase()\nprint('Simple GridWorld:')\ngwb.draw()\ngwb.plan()\nprint('Random policy:')\ngwb.draw(True)","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GridWorldPlanner(GridWorldBase):\n  \"\"\"A GridWorld that finds a better policy.\"\"\"\n\n  def plan(self):\n    \"\"\"Define a better planner!\n\n    This gives you a starting point by setting the proper actions in the cells\n    surrounding the goal cell.\n\n    **Assignment:** Do the rest!\n    \"\"\"\n    super().plan()\n    goal_queue = [self.goal_cell]\n    goals_done = set()\n    goal = goal_queue.pop(0)  # pop from front of list\n    goal_neighbours = self.get_neighbours(goal)\n    goals_done.add(tuple(goal))\n\n    for a in goal_neighbours:\n      nbr = tuple(goal_neighbours[a])\n      if nbr == goal:\n        continue\n      if nbr not in goals_done:\n        if a == '<':\n          self.policy[nbr[0], nbr[1]] = '>'\n        elif a == '>':\n          self.policy[nbr[0], nbr[1]] = '<'\n        elif a == '^':\n          self.policy[nbr[0], nbr[1]] = 'v'\n        else:\n          self.policy[nbr[0], nbr[1]] = '^'\n        goal_queue.append(nbr)\n\n\ngwp = GridWorldPlanner()\nprint('Simple GridWorld:')\ngwp.draw()\ngwp.plan()\nprint('Better policy:')\ngwp.draw(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make a better planner!","metadata":{"execution":{}}},{"cell_type":"code","source":"class GridWorldPlanner(GridWorldBase):\n  \"\"\"A GridWorld that finds a better policy.\"\"\"\n\n  def plan(self):\n    \"\"\"Define a better planner!\n\n    This gives you a starting point by setting the proper actions in the cells\n    surrounding the goal cell.\n\n    **Assignment:** Do the rest!\n    \"\"\"\n    super().plan()\n    goal_queue = [self.goal_cell]\n    goals_done = set()\n    #################################################\n    # Implement a better planer\n    #################################################\n    while goal_queue:\n      goal = goal_queue.pop(0)  # pop from front of list\n      goal_neighbours = self.get_neighbours(goal)\n      goals_done.add(tuple(goal))\n      for a in goal_neighbours:\n        nbr = tuple(goal_neighbours[a])\n        if nbr == goal:\n          continue\n        if nbr not in goals_done:\n          if a == '<':\n            self.policy[nbr[0], nbr[1]] = '>'\n          elif a == '>':\n            self.policy[nbr[0], nbr[1]] = '<'\n          elif a == '^':\n            self.policy[nbr[0], nbr[1]] = 'v'\n          else:\n            self.policy[nbr[0], nbr[1]] = '^'\n          goal_queue.append(nbr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_32802337.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"gwp = GridWorldPlanner()\nprint('Simple GridWorld:')\ngwp.draw()\ngwp.plan()\nprint('Better policy:')\ngwp.draw(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Make_a_better_planner_Exercise\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Try it out in a harder problem.\nharder_grid = np.array(\n    [['*', '*', '*', '*', '*', '*', '*', '*', '*'],\n     ['*', ' ', ' ', ' ', '*', ' ', ' ', 'g', '*'],\n     ['*', ' ', ' ', ' ', '*', ' ', ' ', ' ', '*'],\n     ['*', ' ', ' ', ' ', '*', ' ', ' ', ' ', '*'],\n     ['*', ' ', ' ', ' ', '*', ' ', ' ', ' ', '*'],\n     ['*', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '*'],\n     ['*', '*', '*', '*', '*', '*', '*', '*', '*'],\n    ]\n)\ngwb_2 = GridWorldBase(harder_grid)\ngwp_2 = GridWorldPlanner(harder_grid)\nprint('Harder GridWorld:')\ngwb_2.draw()\ngwb_2.plan()\nprint('Random policy:')\ngwb_2.draw(True)\nprint('Better policy:')\ngwp_2.plan()\ngwp_2.draw(True)","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 2.2: Markov Decision Process (MDP)\n\nFormulating RL problems traditionally happens via a Markov decision process (MDP). In this section, we will introduce all the necessary notation and write code to define the MDP corresponding to our simple GridWorld.\n\n**Extra:** Martin Puterman's [book on Markov Decision Processes](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316887) is an excellent reference if you'd like to read more.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 3: Markov Decision Process\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'AfIsG1I4MRE'), ('Bilibili', 'BV1VV411M7pX')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Markov_Decision_Process_Video\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Coding exercise 2: Create an MDP from the GridWorld specification\n\nCreate $P$ and $R$ matrices for MDP.","metadata":{"execution":{}}},{"cell_type":"code","source":"class MDPBase(object):\n  \"\"\"This object creates a proper MDP from a GridWorld object.\"\"\"\n\n  def __init__(self, grid_world: GridWorldBase):\n    \"\"\"Constructs an MDP from a GridWorldBase object.\n\n    Args:\n      grid_world: GridWorld specification.\n    \"\"\"\n    # Determine how many valid states there are and create empty matrices.\n    self.grid_world = grid_world\n    self.num_states = np.sum(grid_world.world_spec != '*')\n    self.num_actions = len(ACTIONS)\n    self.P = np.zeros((self.num_states, self.num_actions, self.num_states))\n    self.R = np.zeros((self.num_states, self.num_actions))\n    self.pi = np.zeros(self.num_states, dtype=np.int32)\n    # Create mapping from cell positions to state ID.\n    state_idx = 0\n    self.cell_to_state = np.ones(grid_world.world_spec.shape, dtype=np.int32) * -1  # Defaults to -1.\n    self.state_to_cell = {}\n    for i, row in enumerate(grid_world.world_spec):\n      for j, cell in enumerate(row):\n        if cell == '*':\n          continue\n        if cell == 'g':\n          self.goal_state = state_idx\n        self.cell_to_state[i, j] = state_idx\n        self.state_to_cell[state_idx] = (i, j)\n        state_idx += 1\n    #################################################\n    # States should be numbered from left-to-right and from top-to-bottom.\n    #################################################\n    # Assign transition probabilities and rewards accordingly.\n    for s in range(self.num_states):\n      neighbours = grid_world.get_neighbours(self.state_to_cell[s])\n      for a, action in enumerate(neighbours):\n        nbr = neighbours[action]\n        s2 = self.cell_to_state[nbr[0], nbr[1]]\n        self.P[s, a, s2] = 1.0  # Deterministic transitions\n        if s2 == self.goal_state:\n          self.R[s, a] = 1.0\n\n  def draw(self, include_policy: bool = False):\n    # First make sure we convert our MDP policy into the GridWorld policy.\n    for s in range(self.num_states):\n      r, c = self.state_to_cell[s]\n      self.grid_world.policy[r, c] = ACTIONS[self.pi[s]]\n    self.grid_world.draw(include_policy)\n\n  def plan(self):\n    \"\"\"Define a planner\n    \"\"\"\n    goal_queue = [self.goal_state]\n    goals_done = set()\n    #################################################\n    # Set the proper actions\n    #################################################\n    while goal_queue:\n      goal = goal_queue.pop(0)  # pop from front of list\n      nbr_states, nbr_actions = np.where(self.P[:, :, goal] > 0.)\n      goals_done.add(goal)\n      for s, a in zip(nbr_states, nbr_actions):\n        if s == goal:\n          continue\n        if s not in goals_done:\n          self.pi[s] = a\n          goal_queue.append(s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_0102ee70.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"mdpb = MDPBase(gwb)\n\n# Verify the transitions were properly created.\nfor i, row in enumerate(mdpb.grid_world.world_spec):\n  for j, cell in enumerate(row):\n    if cell == '*':\n      continue\n    neighbours = mdpb.grid_world.get_neighbours((i, j))\n    s = mdpb.cell_to_state[i, j]\n    for a, action in enumerate(neighbours):\n      nbr = neighbours[action]\n      s2 = mdpb.cell_to_state[nbr[0], nbr[1]]\n      assert np.sum(mdpb.P[s, a, :]) == 1.0\n      assert mdpb.P[s, a, s2] == 1.0\n      if s2 == mdpb.goal_state:\n        assert mdpb.R[s, a] == 1.0\n      else:\n        assert mdpb.R[s, a] == 0.0\n\nprint('P and R matrices successfully created!')\nprint('GridWorld:')\nmdpb.draw()\nprint('Shortest path policy:')\nmdpb.plan()\nmdpb.draw(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Create_an_MDP_Exercise\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 2.3: $Q$-values\n\n$Q$-values are central to RL algorithms, as they quantify the *desirability* of performing an action given a particular state. The agent updates these values throughout training and can use its estimates to decide how to act.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 4: Q-values\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'u2-uqRiJHuM'), ('Bilibili', 'BV1gk4y1M7iK')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Q_values_Video\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Coding exercise 3: Create a steps-to-go solver\n\nCreate a new MDP class that holds steps-to-go as Q-values","metadata":{"execution":{}}},{"cell_type":"code","source":"class MDPToGo(MDPBase):\n\n  def __init__(self, grid_world: GridWorldBase):\n    \"\"\"Constructs an MDP from a GridWorldBase object.\n\n    States should be numbered from left-to-right and from top-to-bottom.\n\n    Args:\n      grid_world: GridWorld specification.\n    \"\"\"\n    super().__init__(grid_world)\n    self.Q = np.zeros((self.num_states, self.num_actions))\n\n  def computeQ(self):\n    \"\"\"Store discounted steps-to-go in an SxA matrix called Q.\n\n    This matrix will then be used to extract the optimal policy.\n    \"\"\"\n    #################################################\n    # Implement a function to compute Q\n    #################################################\n    goal_queue = [(self.goal_state, 0)]\n    goals_done = set()\n    while goal_queue:\n      goal, steps_to_go = goal_queue.pop(0)  # pop from front of list\n      steps_to_go += 1  # Increase the number of steps to goal.\n      nbr_states, nbr_actions = np.where(self.P[:, :, goal] > 0.)\n      goals_done.add(goal)\n      for s, a in zip(nbr_states, nbr_actions):\n        if goal == self.goal_state and s == self.goal_state:\n          self.Q[s, a] = 0\n        elif s == goal:\n          # If (s, a) leads to itself then we have an infinite loop (since\n          # we're assuming deterministic transitions).\n          self.Q[s, a] = np.inf\n        else:\n          self.Q[s, a] = steps_to_go\n        if s not in goals_done:\n          goal_queue.append((s, steps_to_go))\n\n  def plan(self):\n    \"\"\"Now planning is just doing an argmin over the Q-values!\n\n    Note that this is a little different than standard Q-learning (where we do\n    an argmax), since our Q-values currently store steps-to-go.\n    \"\"\"\n    self.pi = np.argmin(self.Q, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_0f69d259.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"mdpTg = MDPToGo(gwb)\nprint('GridWorld:')\nmdpTg.draw()\n# Compute Q, then extract policy from it.\nmdpTg.computeQ()\nmdpTg.plan()\nprint('Optimal policy:')\nmdpTg.draw(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Create_a_step_to_go_solver_Exercise\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Section 3: Value iteration\n\nValue iteration is an iterative algorithm that continuously improves estimates of $Q$ and $V$ by performing the *Bellman backup*. This assumes access to $P$ and $R$ (not typically accessible in RL) but is the backbone of $Q$-learning, which we will discuss later.\n\n<br>\n\n> *Did you know?* Richard Bellman developed dynamic programming (a core part of any computer science curriculum) precisely for value iteration.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 5: Value iteration\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'XIcX37uaRF0'), ('Bilibili', 'BV1SF41197kC')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Value_Iteration_Video\")","metadata":{"cellView":"form","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Coding exercise 4: Implement value iteration\n\nCreate a new MDP class that does value iteration","metadata":{"execution":{}}},{"cell_type":"code","source":"class MDPValueIteration(MDPToGo):\n\n  def __init__(self, grid_world: GridWorldBase, gamma: float = 0.99):\n    \"\"\"Constructs an MDP from a GridWorldBase object.\n\n    States should be numbered from left-to-right and from top-to-bottom.\n\n    Args:\n      grid_world: GridWorld specification.\n      gamma: Discount factor.\n    \"\"\"\n    super().__init__(grid_world)\n    self.gamma = gamma\n\n  def computeQ(self, error_tolerance : float = 1e-5):\n    \"\"\"Compute Q and V vectors via value iteration.\n\n    Args:\n      error_tolerance: How much error we tolerate between successive Q updates.\n    \"\"\"\n    self.Q = np.zeros((self.num_states, self.num_actions))\n    num_iterations = 0\n    error = np.inf\n    #################################################\n    # Write this method!\n    # First find Q, and then extract V from Q.\n    # Hint: Use matrix multiplication instead of for loops!\n    #################################################\n    while error > error_tolerance:\n      new_Q = np.zeros_like(self.Q)\n      max_next_Q = np.max(self.Q, axis=-1)\n      for a in range(self.num_actions):\n        new_Q[:, a] = self.R[:, a] + self.gamma * (self.P[:, a, :] @ max_next_Q)\n      error = np.max(abs(new_Q - self.Q))\n      self.Q = np.copy(new_Q)\n      num_iterations += 1\n    self.V = np.max(self.Q, axis=-1)\n    print(f'Q and V found in {num_iterations} iterations with an error tolerance of {error_tolerance}.')\n\n  def plan(self):\n    \"\"\"Now planning is just doing an argmax over the Q-values!\n    \"\"\"\n    #################################################\n    # Note that we're going back to argmax, since the Q-values now represent proper\n    # \"returns-to-go\", so we want to maximize that.\n    # Write this method! It should be a one-liner, and very similar to what you\n    # used for extracting V from Q.\n    #################################################\n    self.pi = np.argmax(self.Q, axis=-1)\n\n  def _draw_v(self):\n    \"\"\"Draw the V values.\"\"\"\n    min_v = np.min(self.V)\n    max_v = np.max(self.V)\n    wall_v = 2 * min_v - max_v  # Creating a smaller value for walls.\n    grid_values = np.ones_like(self.grid_world.world_spec, dtype=np.int32) * wall_v\n    # Fill in the V values in grid cells.\n    for s in range(self.num_states):\n      cell = self.state_to_cell[s]\n      grid_values[cell[0], cell[1]] = self.V[s]\n\n    fig, ax = plt.subplots()\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    grid = ax.matshow(grid_values)\n    grid.set_clim(wall_v, max_v)\n    fig.colorbar(grid)\n\n  def draw(self, draw_mode: str = 'grid'):\n    \"\"\"Draw the GridWorld according to specified mode.\n\n    Args:\n      draw_mode: Specification of what mode to draw. Supported options:\n                 'grid': Draw the base GridWorld.\n                 'policy': Display the policy.\n                 'values': Display the values for each state.\n    \"\"\"\n    # First make sure we convert our MDP policy into the GridWorld policy.\n    if draw_mode == 'values':\n      self._draw_v()\n    else:\n      super().draw(draw_mode == 'policy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_fa9d3f4b.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"mdpVi = MDPValueIteration(gwb)\nprint('GridWorld:')\nmdpVi.draw()\n# Compute Q, then extract policy from it.\nmdpVi.computeQ()\nmdpVi.plan()\nprint('Optimal policy:')\nmdpVi.draw('policy')\nmdpVi.draw('values')","metadata":{"execution":{"iopub.status.idle":"2024-07-30T22:32:43.992717Z","shell.execute_reply.started":"2024-07-30T22:32:43.599893Z","shell.execute_reply":"2024-07-30T22:32:43.991356Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Implement_Value_Iteration_Exercise\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:43.998488Z","iopub.execute_input":"2024-07-30T22:32:43.998888Z","iopub.status.idle":"2024-07-30T22:32:44.042985Z","shell.execute_reply.started":"2024-07-30T22:32:43.998854Z","shell.execute_reply":"2024-07-30T22:32:44.041599Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6daff28f8ce942dfa173122ed1825e58"}},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Section 4: Policy iteration\n\nRather than iterating on estimates of $Q$ and $V$ until we've reached some form of convergence, why not iterate directly on the policy $\\pi$ instead?\n\nPolicy iteration does just that and can sometimes lead to solutions in fewer steps than value iteration.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 6: Policy iteration\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'Z77kVYiRm_4'), ('Bilibili', 'BV17u411b7R1')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:44.044460Z","iopub.execute_input":"2024-07-30T22:32:44.044836Z","iopub.status.idle":"2024-07-30T22:32:44.165251Z","shell.execute_reply.started":"2024-07-30T22:32:44.044802Z","shell.execute_reply":"2024-07-30T22:32:44.164163Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2adebf40a3064022bc976c82fa719c6f"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Policy_Iteration_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:44.166981Z","iopub.execute_input":"2024-07-30T22:32:44.167415Z","iopub.status.idle":"2024-07-30T22:32:44.217200Z","shell.execute_reply.started":"2024-07-30T22:32:44.167374Z","shell.execute_reply":"2024-07-30T22:32:44.215736Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4488197f3a3f4996947fb6825353b8c1"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Coding exercise 5: Implement policy iteration\n\nCreate a new MDP class that does policy iteration.","metadata":{"execution":{}}},{"cell_type":"code","source":"class MDPPolicyIteration(MDPToGo):\n\n  def __init__(self, grid_world: GridWorldBase, gamma: float = 0.99):\n    \"\"\"Constructs an MDP from a GridWorldBase object.\n\n    States should be numbered from left-to-right and from top-to-bottom.\n\n    Args:\n      grid_world: GridWorld specification.\n      gamma: Discount factor.\n    \"\"\"\n    super().__init__(grid_world)\n    self.gamma = gamma\n\n  def findPi(self):\n    \"\"\"Find π policy.\n    \"\"\"\n    self.Q = np.zeros((self.num_states, self.num_actions))\n    self.pi = np.zeros(self.num_states, dtype=np.int32)\n    num_iterations = 0\n    #################################################\n    # Compute π, which involves computing Q.\n    # Once you have π and Q, find V.\n    # Hint: Your value iteration solution will be useful here.\n    #################################################\n    new_pi = np.ones_like(self.pi)  # initialize to ones\n    while np.any(new_pi != self.pi):\n      new_pi = self.pi\n      new_Q = np.zeros_like(self.Q)  # initialize to zeros\n      next_V = np.array([mdpVi.Q[i, x] for i, x in enumerate(mdpVi.pi)])\n      for a in range(self.num_actions):\n        new_Q[:, a] = self.R[:, a] + self.gamma * np.matmul(self.P[:, a, :], next_V)\n      self.Q = np.copy(new_Q)\n      self.pi = np.argmax(self.Q, axis=-1)\n      num_iterations += 1\n    self.V = np.max(self.Q, axis=-1)\n    print(f'Q and V found in {num_iterations} iterations.')\n\n  def _draw_v(self):\n    \"\"\"Draw the V values.\"\"\"\n    min_v = np.min(self.V)\n    max_v = np.max(self.V)\n    wall_v = 2 * min_v - max_v  # Creating a smaller value for walls.\n    grid_values = np.ones_like(self.grid_world.world_spec, dtype=np.int32) * wall_v\n    # Fill in the V values in grid cells.\n    for s in range(self.num_states):\n      cell = self.state_to_cell[s]\n      grid_values[cell[0], cell[1]] = self.V[s]\n\n    fig, ax = plt.subplots()\n    ax.grid(False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    grid = ax.matshow(grid_values)\n    grid.set_clim(wall_v, max_v)\n    fig.colorbar(grid)\n\n  def draw(self, draw_mode: str = 'grid'):\n    \"\"\"Draw the GridWorld according to specified mode.\n\n    Args:\n      draw_mode: Specification of what mode to draw. Supported options:\n                 'grid': Draw the base GridWorld.\n                 'policy': Display the policy.\n                 'values': Display the values for each state.\n    \"\"\"\n    # First make sure we convert our MDP policy into the GridWorld policy.\n    if draw_mode == 'values':\n      self._draw_v()\n    else:\n      super().draw(draw_mode == 'policy')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T22:32:44.219172Z","iopub.execute_input":"2024-07-30T22:32:44.219683Z","iopub.status.idle":"2024-07-30T22:32:44.245817Z","shell.execute_reply.started":"2024-07-30T22:32:44.219616Z","shell.execute_reply":"2024-07-30T22:32:44.244364Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_63c032bf.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"mdpPi = MDPPolicyIteration(gwb)\nprint('GridWorld:')\nmdpPi.draw()\n# Compute Q, then extract policy from it.\nmdpPi.findPi()\nprint('Optimal policy:')\nmdpPi.draw('policy')\nmdpPi.draw('values')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T22:32:44.247383Z","iopub.execute_input":"2024-07-30T22:32:44.247879Z","iopub.status.idle":"2024-07-30T22:32:44.532214Z","shell.execute_reply.started":"2024-07-30T22:32:44.247847Z","shell.execute_reply":"2024-07-30T22:32:44.531038Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"GridWorld:\n⬛⬛⬛⬛⬛⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⭐⬛\n⬛⬛⬛⬛⬛⬛\nQ and V found in 2 iterations.\nOptimal policy:\n⬛⬛⬛⬛⬛⬛\n⬛▶️▶️▶️🔽⬛\n⬛▶️▶️▶️🔽⬛\n⬛▶️▶️▶️🔽⬛\n⬛▶️▶️▶️⭐⬛\n⬛⬛⬛⬛⬛⬛\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Implement_Policy_Iteration_Exercise\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:44.534060Z","iopub.execute_input":"2024-07-30T22:32:44.535109Z","iopub.status.idle":"2024-07-30T22:32:44.579733Z","shell.execute_reply.started":"2024-07-30T22:32:44.535055Z","shell.execute_reply":"2024-07-30T22:32:44.578036Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec920cc7b00441c29eb26e11ab1153fa"}},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Section 5: $Q$-learning algorithm\n\nRL assumes we don't have access to $P$ nor $R$, so we can use neither value nor policy iteration to find an optimal behavior for our agent.\n\n$Q$-learning, however, incorporates the Bellman backup into an online learning algorithm: $Q$-learning, which can be shown to converge to the true $Q$-values (under mild conditions)!","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 7: Q-learning\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'HqOdNTdpppE'), ('Bilibili', 'BV1az4y1n7pb')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:44.581396Z","iopub.execute_input":"2024-07-30T22:32:44.581905Z","iopub.status.idle":"2024-07-30T22:32:44.677212Z","shell.execute_reply.started":"2024-07-30T22:32:44.581859Z","shell.execute_reply":"2024-07-30T22:32:44.675903Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64eca4ee35db487f840788bde2a801c2"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Q_learning_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:44.678419Z","iopub.execute_input":"2024-07-30T22:32:44.678765Z","iopub.status.idle":"2024-07-30T22:32:44.723721Z","shell.execute_reply.started":"2024-07-30T22:32:44.678735Z","shell.execute_reply":"2024-07-30T22:32:44.722173Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08e93ed12cc40fb885cce0ec8aa5620"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Coding exercise 6: Implement Q-learning\n\nCreate a Q-learning class","metadata":{"execution":{}}},{"cell_type":"code","source":"class QLearner(MDPValueIteration):\n\n  def __init__(self, grid_world: GridWorldBase, gamma: float = 0.99):\n    \"\"\"Constructs an MDP from a GridWorldBase object.\n\n    States should be numbered from left-to-right and from top-to-bottom.\n\n    Args:\n      grid_world: GridWorld specification.\n      gamma: Discount factor.\n    \"\"\"\n    super().__init__(grid_world, gamma)\n    self.Q = np.zeros((self.num_states, self.num_actions))\n    # Pick an initial state randomly.\n    self.current_state = np.random.choice(self.num_states)\n\n  def step(self, action: int) -> Tuple[int, float]:\n    \"\"\"Take a step in MDP from self.current_state.\n\n    Args:\n      action: Action to take.\n\n    Returns:\n      Next state and reward received.\n    \"\"\"\n    new_state = np.random.choice(self.num_states,\n                                 p=self.P[self.current_state, action, :])\n    return (new_state, self.R[self.current_state, action])\n\n  def pickAction(self) -> int:\n    \"\"\"Pick the best action from the current state and Q-value estimates.\"\"\"\n    return np.argmax(self.Q[self.current_state, :])\n\n  def maybeReset(self):\n    \"\"\"If current_state is goal, reset to a random state.\"\"\"\n    if self.current_state == self.goal_state:\n      self.current_state = np.random.choice(self.num_states)\n\n  def learnQ(self, alpha: float = 0.1, max_steps: int = 10_000):\n    \"\"\"Learn the Q-function by interacting with the environment.\n\n    Args:\n      alpha: Learning rate.\n      max_steps: Maximum number of steps to take.\n    \"\"\"\n    self.Q = np.ones((self.num_states, self.num_actions))\n    num_steps = 0\n    #################################################\n    # Hint: Use the step(), pickAction(), and maybeReset() functions above.\n    # Note: The way you initialize the Q-values is crucial here. Try first with\n    # an all-zeros initialization (as is currently coded below). If it doesn't\n    # work, try a different initialization.\n    # Hint: The maximum possible value (given the rewards are in [0, 1]) is\n    #       1 / (1 - gamma).\n    #################################################\n    while num_steps < max_steps:\n      a = self.pickAction()\n      new_state, r = self.step(a)\n      td = r + self.gamma * np.max(self.Q[new_state, :]) - self.Q[self.current_state, a]\n      self.Q[self.current_state, a] += alpha * td\n      self.current_state = new_state\n      self.maybeReset()\n      num_steps += 1\n    self.V = np.max(self.Q, axis=-1)\n\n\n  def plan(self):\n    \"\"\"Now planning is just doing an argmin over the Q-values!\n\n    Note that this is a little different than standard Q-learning (where we do\n    an argmax), since our Q-values currently store steps-to-go.\n    \"\"\"\n    self.pi = np.argmax(self.Q, axis=-1)\n    self.V = np.max(self.Q, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T22:32:44.725035Z","iopub.execute_input":"2024-07-30T22:32:44.725371Z","iopub.status.idle":"2024-07-30T22:32:44.742023Z","shell.execute_reply.started":"2024-07-30T22:32:44.725341Z","shell.execute_reply":"2024-07-30T22:32:44.740725Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_54192b12.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"base_q_learner = QLearner(gwb)\nprint('GridWorld:')\nbase_q_learner.draw()\n# Compute Q, then extract policy from it.\nbase_q_learner.learnQ()\nbase_q_learner.plan()\nprint('Optimal policy:')\nbase_q_learner.draw('policy')\nbase_q_learner.draw('values')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T22:32:44.743724Z","iopub.execute_input":"2024-07-30T22:32:44.744076Z","iopub.status.idle":"2024-07-30T22:32:45.671368Z","shell.execute_reply.started":"2024-07-30T22:32:44.744045Z","shell.execute_reply":"2024-07-30T22:32:45.670115Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"GridWorld:\n⬛⬛⬛⬛⬛⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⭐⬛\n⬛⬛⬛⬛⬛⬛\nOptimal policy:\n⬛⬛⬛⬛⬛⬛\n⬛🔽🔽🔽🔽⬛\n⬛🔽🔽🔽🔽⬛\n⬛▶️🔽▶️🔽⬛\n⬛▶️▶️▶️⭐⬛\n⬛⬛⬛⬛⬛⬛\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Implement_Q_learning_Exercise\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:45.672816Z","iopub.execute_input":"2024-07-30T22:32:45.673159Z","iopub.status.idle":"2024-07-30T22:32:45.717395Z","shell.execute_reply.started":"2024-07-30T22:32:45.673129Z","shell.execute_reply":"2024-07-30T22:32:45.716245Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d78389bd074069a6359ef87f6ff4d4"}},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Section 6: $\\epsilon$-greedy exploitation\n\nShould an agent *exploit* its current estimates and policy, or should it *explore* the environment in case better policies are out there? This *exploration-exploitation dilemma* is a central problem in RL.\n\nIn this section, we explore one of the simplest yet most effective methods for this tradeoff: the so-called $\\epsilon$-greedy exploration.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 8: Epsilon-greedy exploration\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'NiF7_RK_4M4'), ('Bilibili', 'BV1Jh4y1u78c')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:45.719151Z","iopub.execute_input":"2024-07-30T22:32:45.719483Z","iopub.status.idle":"2024-07-30T22:32:45.829921Z","shell.execute_reply.started":"2024-07-30T22:32:45.719454Z","shell.execute_reply":"2024-07-30T22:32:45.828727Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e256e546714bbebbd24b8b93e531f1"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Epsilon_greedy_exploration_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:32:45.831594Z","iopub.execute_input":"2024-07-30T22:32:45.832063Z","iopub.status.idle":"2024-07-30T22:32:45.878356Z","shell.execute_reply.started":"2024-07-30T22:32:45.832011Z","shell.execute_reply":"2024-07-30T22:32:45.876989Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d475c9d1ca6c481987d778a26b74c311"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Coding exercise 7: Implement epsilon-greedy exploration\n\nCreate a Q-learning class with epsilon-greedy exploration","metadata":{"execution":{}}},{"cell_type":"code","source":"class QLearnerExplorer(QLearner):\n\n  def __init__(self, grid_world: GridWorldBase, gamma: float = 0.99,\n               epsilon: float = 0.1):\n    \"\"\"Constructs an MDP from a GridWorldBase object.\n\n    States should be numbered from left-to-right and from top-to-bottom.\n\n    Args:\n      grid_world: GridWorld specification.\n      gamma: Discount factor.\n      epsilon: Exploration rate.\n    \"\"\"\n    super().__init__(grid_world, gamma)\n    self.epsilon = epsilon\n\n  def pickAction(self):\n    \"\"\"Pick the next action from the current state.\n    \"\"\"\n    #################################################\n    # With probability epsilon will pick the next action randomly, otherwise will\n    # pick based on the Q-value estimates.\n    # Hint: It should only be a few lines of code!\n    #################################################\n    if np.random.rand() < self.epsilon:\n      return np.random.choice(self.num_actions)\n    return np.argmax(self.Q[self.current_state, :])","metadata":{"execution":{"iopub.status.busy":"2024-07-30T22:33:32.622252Z","iopub.execute_input":"2024-07-30T22:33:32.622965Z","iopub.status.idle":"2024-07-30T22:33:32.633546Z","shell.execute_reply.started":"2024-07-30T22:33:32.622920Z","shell.execute_reply":"2024-07-30T22:33:32.632034Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W3D4_BasicReinforcementLearning/solutions/W3D4_Tutorial1_Solution_4743dbd3.py)\n\n","metadata":{"colab_type":"text","execution":{}}},{"cell_type":"code","source":"explorer = QLearnerExplorer(gwb)\nprint('GridWorld:')\nexplorer.draw()\n# Compute Q, then extract policy from it.\nexplorer.learnQ()\nexplorer.plan()\nprint('Optimal policy:')\nexplorer.draw('policy')\nexplorer.draw('values')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T22:33:34.208209Z","iopub.execute_input":"2024-07-30T22:33:34.208717Z","iopub.status.idle":"2024-07-30T22:33:35.097090Z","shell.execute_reply.started":"2024-07-30T22:33:34.208679Z","shell.execute_reply":"2024-07-30T22:33:35.095624Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"GridWorld:\n⬛⬛⬛⬛⬛⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⬜⬛\n⬛⬜⬜⬜⭐⬛\n⬛⬛⬛⬛⬛⬛\nOptimal policy:\n⬛⬛⬛⬛⬛⬛\n⬛🔽🔽🔽🔽⬛\n⬛▶️🔽🔽🔽⬛\n⬛▶️🔽▶️🔽⬛\n⬛▶️▶️▶️⭐⬛\n⬛⬛⬛⬛⬛⬛\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Implement_epsilon_greedy_exploration_Exercise\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-30T22:33:40.296014Z","iopub.execute_input":"2024-07-30T22:33:40.296792Z","iopub.status.idle":"2024-07-30T22:33:40.343730Z","shell.execute_reply.started":"2024-07-30T22:33:40.296744Z","shell.execute_reply":"2024-07-30T22:33:40.341998Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='🙂', layout=Layout(height='auto', padding='0.5…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ad8267c0344b47904e78da36b69657"}},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Summary\n\nReinforcement learning is important in artificial intelligence because it allows an agent to learn how to make decisions in complex environments based on trial and error. Understanding how an agent learns and the various algorithms used to facilitate this learning is crucial for developing effective RL systems.\n\n* The Gridworld environment is a commonly used testbed for RL algorithms and provides a simple yet challenging environment for agents to learn in. By mastering the Gridworld environment, researchers can apply the same principles to more complex tasks.\n\n* $Q$-values are a fundamental concept in RL, representing the expected reward an agent will receive by taking a certain action in a given state. Computing $Q$-values is essential for many RL algorithms, including $Q$-learning.\n\n* The value and policy iteration algorithms are important because they provide a way to compute optimal policies for an agent in a given environment. These algorithms help an agent make decisions leading to the greatest cumulative reward over time.\n\n* $Q$-learning is a widely used RL algorithm known for its simplicity and effectiveness. It is essential because it allows an agent to learn how to make decisions in an environment without requiring a model of the environment and can be applied to a wide range of tasks.\n\n* Finally, $\\epsilon$-greedy exploration is an important concept in RL because it helps to balance the exploration-exploitation tradeoff. Occasionally choosing a random action allows an agent to explore new areas of the environment and potentially discover better policies.\n\n","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n# Daily survey\n\nDon't forget to complete your reflections and content check in the daily survey! Please be patient after logging in as there is a small delay before you will be redirected to the survey.\n\n<a href=\"https://portal.neuromatchacademy.org/api/redirect/to/e0de4042-c7df-4b7e-a00b-b3cfc05f8d49\"><img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\" alt=\"button link to survey\" style=\"width:410px\"></a>","metadata":{"execution":{}}}]}