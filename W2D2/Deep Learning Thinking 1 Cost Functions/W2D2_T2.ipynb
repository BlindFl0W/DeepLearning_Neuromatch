{"metadata":{"colab":{"collapsed_sections":[],"include_colab_link":true,"name":"W2D2_Tutorial2","provenance":[],"toc_visible":true},"kernel":{"display_name":"Python 3","language":"python","name":"python3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>","metadata":{"colab_type":"text","execution":{},"id":"view-in-github"}},{"cell_type":"markdown","source":"# Tutorial 2: Deep Learning Thinking 1: Cost Functions\n\n**Week 2, Day 2: Convnets and DL Thinking**\n\n**By Neuromatch Academy**\n\n\n__Content creators:__ Konrad Kording, Lyle ungar, Ashish Sahoo\n\n__Content reviewers:__ Kelson Shilling-Scrivo\n\n__Content editors:__ Kelson Shilling-Scrivo\n\n__Production editors:__ Gagana B, Spiros Chavlis","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n# Tutorial Objectives\n\nIn this tutorial, you will practice thinking like a deep learning practitioner and determine how to design cost functions for different scenarios.\n\nBy the end of this tutorial, you will be better able to:\n\n* Appreciate the importance of cost function engineering\n* Translate domain knowledge into cost functions\n* Ask questions about DL systems and customer needs","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Tutorial slides\nfrom IPython.display import IFrame\nlink_id = \"szcjn\"\nprint(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\nIFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:18.454219Z","iopub.execute_input":"2024-07-16T20:58:18.455025Z","iopub.status.idle":"2024-07-16T20:58:18.500641Z","shell.execute_reply.started":"2024-07-16T20:58:18.454982Z","shell.execute_reply":"2024-07-16T20:58:18.499513Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"If you want to download the slides: https://osf.io/download/szcjn/\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.IFrame at 0x7f8dad3585b0>","text/html":"\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/szcjn/?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Setup","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Install and import feedback gadget\n\n!pip3 install vibecheck datatops --quiet\n\nfrom vibecheck import DatatopsContentReviewContainer\ndef content_review(notebook_section: str):\n    return DatatopsContentReviewContainer(\n        \"\",  # No text prompt\n        notebook_section,\n        {\n            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n            \"name\": \"neuromatch_dl\",\n            \"user_key\": \"f379rz8y\",\n        },\n    ).render()\n\n\nfeedback_prefix = \"W2D2_T2\"","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:18.502339Z","iopub.execute_input":"2024-07-16T20:58:18.502688Z","iopub.status.idle":"2024-07-16T20:58:41.975965Z","shell.execute_reply.started":"2024-07-16T20:58:18.502658Z","shell.execute_reply":"2024-07-16T20:58:41.974588Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"---\n# Section 1: Intro to Deep Learning Thinking\n\n\n\n\n\n\n\n","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 1: Intro to DL Thinking\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'iEqd0MY5pxI'), ('Bilibili', 'BV1hL4y1P73s')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:41.977985Z","iopub.execute_input":"2024-07-16T20:58:41.978346Z","iopub.status.idle":"2024-07-16T20:58:42.048817Z","shell.execute_reply.started":"2024-07-16T20:58:41.978306Z","shell.execute_reply":"2024-07-16T20:58:42.047674Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff5c51d06312464aae96b56e018c31b6"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Intro_to_DL_Thinking_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.051632Z","iopub.execute_input":"2024-07-16T20:58:42.052000Z","iopub.status.idle":"2024-07-16T20:58:42.094426Z","shell.execute_reply.started":"2024-07-16T20:58:42.051968Z","shell.execute_reply":"2024-07-16T20:58:42.093192Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"313317822c8246a19dde81825eae752c"}},"metadata":{}}]},{"cell_type":"markdown","source":"This tutorial is a bit different from others - there will be no coding! Instead you will watch a series of vignettes about various scenarios where you want to use a neural network. This tutorial will focus on cost functions, a tutorial you will see later in the course will be similar but focused on designing architectures.\n\nEach section below will start with a vignette where either Lyle or Konrad is trying to figure out how to set up a neural network for a specific problem. Try to think of questions you want to ask them as you watch, then pay attention to what questions Lyle and Konrad are asking. Were they what you would have asked? How do their questions help quickly clarify the situation?\n\n\nYou will work together as a group to try to come up with cost functions for each example, with hints available along the way. This may be difficult - deep learning in the real world often is! So try your best but don't get discouraged if you don't reach the solution - you'll learn a lot from the process of trying to.\n\nYou have already seen cost functions (sometimes also called objective functions or loss functions) for deep neural networks - you need one to perform gradient descent and train a neural network.  It turns out what cost function you choose to minimize is incredibly important - it is how you define success of your network after all, so you want to define success in a good way! And cost functions are not one size fits all - you need to carefully choose cost functions according to what you want your neural network to do - as you will seen in the following scenarios.\n\n\n","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n# Section 2: Cost function for neurons\n","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 2: Spiking Neuron Predictions Vignette\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'CC4gMRrE31g'), ('Bilibili', 'BV1Jt4y187UU')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.096149Z","iopub.execute_input":"2024-07-16T20:58:42.096872Z","iopub.status.idle":"2024-07-16T20:58:42.167340Z","shell.execute_reply.started":"2024-07-16T20:58:42.096829Z","shell.execute_reply":"2024-07-16T20:58:42.166152Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f5f57ac19a46dab051602abb075839"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Spiking_Neuron_Predictions_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.168890Z","iopub.execute_input":"2024-07-16T20:58:42.169267Z","iopub.status.idle":"2024-07-16T20:58:42.210752Z","shell.execute_reply.started":"2024-07-16T20:58:42.169235Z","shell.execute_reply":"2024-07-16T20:58:42.209158Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fbcf9c4fbd148a6bae561dd4df1a3dd"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Video 3: Spiking Neuron Predictions Set-up\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'vJ7MixhmDh8'), ('Bilibili', 'BV1X94y1y7SH')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.213326Z","iopub.execute_input":"2024-07-16T20:58:42.213703Z","iopub.status.idle":"2024-07-16T20:58:42.281076Z","shell.execute_reply.started":"2024-07-16T20:58:42.213670Z","shell.execute_reply":"2024-07-16T20:58:42.279877Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa1f12b580d43a888d029dd30b6b7ff"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Spiking_Neuron_Predictions_SetUp_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.282523Z","iopub.execute_input":"2024-07-16T20:58:42.282875Z","iopub.status.idle":"2024-07-16T20:58:42.326322Z","shell.execute_reply.started":"2024-07-16T20:58:42.282844Z","shell.execute_reply":"2024-07-16T20:58:42.325009Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c656e27af24bdd9bcf4876db030946"}},"metadata":{}}]},{"cell_type":"markdown","source":"Konrad, a neuroscientist, wants to predict what neurons in someone's motor cortex are doing while they are riding a motorcycle.\n\nUpon discussion with Lyle, it emerges that we have data on 12 parameters of motorcycle riding, including acceleration, angle, braking, degrees of leaning. These inputs are fairly smooth over time, the angle of the motorcycle typically does not change much in 100 ms for example.\n\nWe also have recorded data on the timing of spikes of $N$ neurons in motor cortex. The underlying firing rate is smooth but every millisecond spikes are random and independent. This means we can assume that the number of spikes in a short interval can be modeled using a Poisson distribution with an underlying firing rate for that interval $\\lambda$.\n\nFor neuron $i$, the probability of seeing $k_{i}$ spikes in some interval given an underlying firing rate $\\lambda_{i}$ is:\n\n\\begin{equation}\n\\mathcal{f(k_{i}:Î»_{i})} = \\mathcal{Pr(X=k_{i})} = \\frac {\\lambda_{i}^{k_{i}}e^{-\\lambda_{i}}}{k_{i}!}\n\\end{equation}\n\nSo this poisson distribution may be relevant if we want to, in a way, have a good model for the spiking of neurons.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## Think! 1: Designing a cost function to predict neural activities\n\nGiven everything you know, how would you design a cost function for a neural network that Konrad is training to predict neural activity given the motorcycle riding parameters? Remember that we are predicting the activity of all $N$ neurons, not just one. Try to write out an equation!\n\n\nPlease discuss as a group. If you get stuck, you can uncover the hints below one at a time. Please spend some time discussing before uncovering the next hint though! You are being real deep learning scientists now and the answers won't be easy\n","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 1 </font></summary>\n\nYou get time-stamps for the spikes. You will want to do binning into 50 ms bins. You get $k_{i, t}$ for every neuron $i$ and time bin $t$, the spike count for that neuron in that time bin.  What will the neural network predict?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 2 </font></summary>\n\nFor each bin you can use your neural network model to predict an estimate of $\\lambda_{i,t}$, the number of spikes for neuron $i$ expected at that time bin $t$. The network should get as input the relevant aspects of the motorcycle riding at the relevant times (and potentially of the previous times).","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 3 </font></summary>\n\nYou need an equation relating $\\lambda_{i,t}$ (the model prediction) with $k_{i, t}$ (your data) where changing $\\lambda_{i,t}$  to minimize or maximize the number resulting from this equation results in better predictions.  What do we already know about the relationship between $\\lambda_{i,t}$ and $k_{i, t}$ that helps us here?\n\nOnce you have that, how do you extend to incorporate all neurons and time bins?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 4 </font></summary>\n\nWe can treat the bins independently as the spikes are random and independent every millisecond.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for the solution </font></summary>\n\n\nFirst, we will convert our spike timing data to the number of spikes per time bin for time bins of size 50 ms. This gives us $k_{i,t}$ for every neuron $i$ and time bin $t$.\n\nWe are assuming a Poisson distribution for our spiking. That means that we get the probability of seeing spike count $k_{i, t}$  given underlying firing rate $\\lambda_{i, t}$ using this equation:\n\n\n\\begin{equation}\n\\mathcal{f(k_{i,t}:\\lambda_{i,t})} = \\mathcal{Pr}(X=k_{i,t}) = \\frac {\\lambda_{i,t}^{k_{i,t}}e^{-\\lambda_{i,t}}}{k_{i,t}!}\n\\end{equation}\n\nThat seems a pretty good thing to optimize to make our predictions as good as possible! We want a high probability of seeing the actual spike count we recorded given the neural network prediction of the underlying firing rate.\n\nWe will make this negative later so we have an equation that we want to minimize rather than maximize, so we can use all our normal tricks for minimization (instead of maximization). First though, let's scale up to include all our neurons and time bins.\n\nWe can treat each time bin as independent because, while the underlying probability of firing changes slowly, every milisecond spiking is random and independent. From probability, we know that we can compute the probability of a set of independent events (all the spike counts) by multiplying the probabilities of each event. So the probability of seeing all of our data given the neural network predictions is all of our probabilities of $k_{i,t}$ multiplied together:\n\n\\begin{align}\n\\mathcal{Pr}(\\text{all_data}) &= \\prod_{i=1}^{N}\\prod_{t=1}^\\top \\mathcal{Pr}(X=k_{i,t})\\\\\n&= \\prod_{i=1}^{N}\\prod_{t=1}^\\top \\frac {\\lambda_{i,t}^{k_{i,t}}e^{-\\lambda_{i,t}}}{k_{i,t}!}\n\\end{align}\n\nThis is also known as our likelihood!\n\nWe usually use the log likelihood instead of the likelihood when minimizing or maximizing for numerical computation reasons. W We can convert the above equation to log likelihood:\n\n\\begin{align}\n\\text{log likelihood} &= \\sum_{i=1}^N\\sum_{t=1}^\\top \\text{log}(\\mathcal{Pr}(X=k_{i,t}) \\\\\n&= \\sum_{i=1}^N\\sum_{t=1}^\\top k_{i,t} \\text{log}(\\lambda_{i,t}) - \\lambda_{i,t} - \\text{log}(k_{i,t}!)\n\\end{align}\n\nAnd last but not least, we want to make it negative so we can minimize instead of maximize:\n\n\\begin{equation}\n\\text{negative log likelihood}\n= \\sum_{i=1}^N\\sum_{t=1}^\\top - k_{i,t} \\text{log}(\\lambda_{i,t}) + \\lambda_{i,t} + \\text{log}(k_{i,t}!)\n\\end{equation}","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Designing_a_cost_function_to_predict_neural_activities_Discussion\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.327913Z","iopub.execute_input":"2024-07-16T20:58:42.328262Z","iopub.status.idle":"2024-07-16T20:58:42.370265Z","shell.execute_reply.started":"2024-07-16T20:58:42.328233Z","shell.execute_reply":"2024-07-16T20:58:42.369034Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac6ca207a07494ca5b9aa8bc6a90679"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Video 4: Spiking Neurons Wrap-up\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'fb6A03B2U5g'), ('Bilibili', 'BV1K94y117rH')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.375044Z","iopub.execute_input":"2024-07-16T20:58:42.375451Z","iopub.status.idle":"2024-07-16T20:58:42.449235Z","shell.execute_reply.started":"2024-07-16T20:58:42.375417Z","shell.execute_reply":"2024-07-16T20:58:42.448243Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d8dee8f3964aefb9dc414128d7e9aa"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Spiking_Neurons_WrapUp_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.450685Z","iopub.execute_input":"2024-07-16T20:58:42.451041Z","iopub.status.idle":"2024-07-16T20:58:42.495479Z","shell.execute_reply.started":"2024-07-16T20:58:42.451010Z","shell.execute_reply":"2024-07-16T20:58:42.494117Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d4a5fb14d3241a1aeb201e041030247"}},"metadata":{}}]},{"cell_type":"markdown","source":"Check out the papers mentioned in the above video:\n\n- [Fast inference in generalized linear models via expected log likelihood](https://link.springer.com/article/10.1007/s10827-013-0466-4)\n\n- [Machine Learning for Neural Decoding](https://www.eneuro.org/content/7/4/ENEURO.0506-19.2020)","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## (Bonus) Think!: Non-Poisson neurons\n\nIf you have time discuss the following. The spiking distributions don't seem quite Poisson.  Find a good replacement for your cost function.","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_NonPoisson_neurons_Bonus_Discussion\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.497212Z","iopub.execute_input":"2024-07-16T20:58:42.497676Z","iopub.status.idle":"2024-07-16T20:58:42.547577Z","shell.execute_reply.started":"2024-07-16T20:58:42.497633Z","shell.execute_reply":"2024-07-16T20:58:42.546278Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad2e242efed944c2b16a75345ed6d2a0"}},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Section 3: How can an ANN know its uncertainty","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 5: ANN Uncertainty Vignette\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'b2N2OJ2u4AM'), ('Bilibili', 'BV1UN4y1u7Ws')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.549302Z","iopub.execute_input":"2024-07-16T20:58:42.549688Z","iopub.status.idle":"2024-07-16T20:58:42.626026Z","shell.execute_reply.started":"2024-07-16T20:58:42.549655Z","shell.execute_reply":"2024-07-16T20:58:42.624885Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66b1aed2dfe45e3aae49d65e56f7c04"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_ANN_Uncertainty_Vignette_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.627369Z","iopub.execute_input":"2024-07-16T20:58:42.627711Z","iopub.status.idle":"2024-07-16T20:58:42.673150Z","shell.execute_reply.started":"2024-07-16T20:58:42.627682Z","shell.execute_reply":"2024-07-16T20:58:42.671731Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cb9178dcaf844798c9df23918aea819"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Video 6: ANN Uncertainty Set-up\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'Reh-gNiOwkQ'), ('Bilibili', 'BV1B34y1W7F8')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.675126Z","iopub.execute_input":"2024-07-16T20:58:42.675608Z","iopub.status.idle":"2024-07-16T20:58:42.743800Z","shell.execute_reply.started":"2024-07-16T20:58:42.675564Z","shell.execute_reply":"2024-07-16T20:58:42.742552Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77baee18a58a4c61b4fc7ef8031c6760"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_ANN_Uncertainty_SetUp_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.745280Z","iopub.execute_input":"2024-07-16T20:58:42.745652Z","iopub.status.idle":"2024-07-16T20:58:42.787765Z","shell.execute_reply.started":"2024-07-16T20:58:42.745621Z","shell.execute_reply":"2024-07-16T20:58:42.786579Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72559a6dcb6a48009e5bd17ea17dc88a"}},"metadata":{}}]},{"cell_type":"markdown","source":"Lyle wants to build an artificial neural network that has a measure of its own uncertainty about it's predictions. He wants the neural network to give a prediction/estimate and an uncertainty, or standard deviation, measurement on it.\n\nLet's say Lyle wants to estimate the location of an atom in a chemical molecule based on various inputs. He wants to have the estimate of the location and an estimate of the variance. We don't train neural networks on one data point at a time though - he wants a cost function that takes in N data points (input and atom location pairings).\n\nWe think we may be able to use a Gaussian distribution to help Lyle here:\n\n\\begin{equation}\ng(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\text{exp} \\left( -\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2} \\right)\n\\end{equation}","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## Think! 2: Designing a cost function so we measure uncertainty\n\nGiven everything you know, how would you design a cost function for a neural network that Lyle is training so that he can get the estimate and the uncertainty of the estimate? Try to write out an equation!\n\nPlease discuss as a group. If you get stuck, you can uncover the hints below one at a time. Please spend some time discussing before uncovering the next hint, though! You are being real deep learning scientists now, and the answers won't be easy.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 1 </font></summary>\n\nLook at the Gaussian equation. What is the true location? Where is there the estimate of location? Where is there the uncertainty?\n\nWhat do you want the neural network to predict for one data point (recorded location) given the inputs?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 2 </font></summary>\n\nWhat did you learn from working through Section 2 that you can use here?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 3 </font></summary>\n\nIn section 2, you learned that you want to go from probabilities to negative log likelihoods to form cost functions.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for the solution </font></summary>\n\nFor a given set of inputs, we want the neural network to predict the location of the atom and the uncertainty of that estimate. Standard deviation is a great measure of uncertainty so we can predict the mean and standard deviation of the location (instead of just the mean as is more common).\n\nSo how do we a design a cost function that involves the mean and standard deviation?  We can assume a Gaussian distribution over the location. The neural network can predict the mean of that Gaussian (that's the estimate of the location) and the standard deviation of that Gaussian (that's the uncertainty measure) for a given set of inputs.\n\nNow that we've got that figured out, we can take a very similar approach to what we did in Section 2 with spiking neurons. For a given data point $i$, the neural network predicts the mean ($\\mu_i$) and standard deviation ($\\sigma_i$) of the location given the inputs. We can then compute the probability of seeing the actual recorded location ($x_i$) given these predictions:\n\n\\begin{equation}\ng(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\text{exp}\\left( -\\frac{1}{2}\\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\right)\n\\end{equation}\n\nThe location of the atom is independent in each data point so we can get the overall likelihood by multiplying the probabilities for the individual data points.\n\\begin{equation}\n\\text{likelihood} = \\prod_{i=1}^N\\frac{1}{\\sigma\\sqrt{2\\pi}} \\text{exp}\\left( -\\frac{1}{2}\\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\right)\n\\end{equation}\n\n\nAnd, as before, we want to take the log of this for numerical reasons and convert to negative log likelihood:\n\n\\begin{equation}\n\\text{negative log likelihood} = \\sum_{i=1}^N \\text{log} \\left( \\frac{1}{\\sigma\\sqrt{2\\pi}} \\text{exp}\\left( -\\frac{1}{2}\\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\right) \\right)\n\\end{equation}\n\nChanging the parameters of the neural network so it predicts $\\mu_i$ and $\\sigma_i$ that minimize this equation will give us (hopefully fairly accurate) predictions of the location and the network uncertainty about the location!","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_ANN_Uncertainty_Discussion\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.789940Z","iopub.execute_input":"2024-07-16T20:58:42.790300Z","iopub.status.idle":"2024-07-16T20:58:42.835232Z","shell.execute_reply.started":"2024-07-16T20:58:42.790269Z","shell.execute_reply":"2024-07-16T20:58:42.833890Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75edf1ec39d42c98a6c44e5071626d1"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Video 7: ANN Uncertainty Wrap-up\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'QBKAFRaC8SY'), ('Bilibili', 'BV1zv4y1M7C8')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.836785Z","iopub.execute_input":"2024-07-16T20:58:42.837150Z","iopub.status.idle":"2024-07-16T20:58:42.903155Z","shell.execute_reply.started":"2024-07-16T20:58:42.837118Z","shell.execute_reply":"2024-07-16T20:58:42.901882Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49479806ae894d04b8b1bfaf6bc8586d"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_ANN_Uncertainty_WrapUp_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.904731Z","iopub.execute_input":"2024-07-16T20:58:42.905113Z","iopub.status.idle":"2024-07-16T20:58:42.946905Z","shell.execute_reply.started":"2024-07-16T20:58:42.905077Z","shell.execute_reply":"2024-07-16T20:58:42.945724Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb1643455d943eba69c29bf35396495"}},"metadata":{}}]},{"cell_type":"markdown","source":"Check out the papers mentioned in the above video:\n\n- [Rapid prediction of NMR spectral properties with quantified uncertainty](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0374-3)\n\n- [Deep imitation learning for molecular inverse problems](https://papers.nips.cc/paper/2019/file/b0bef4c9a6e50d43880191492d4fc827-Paper.pdf)","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## (Bonus) Think!: Negative standard deviations\n\nIf the standard deviation is negative, the negative log-likelihood will fail as you'd take the log of a negative number. What should we do to ensure we don't run into this while training our neural network?","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Negative_standard_deviations_Bonus_Discussion\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.948566Z","iopub.execute_input":"2024-07-16T20:58:42.948926Z","iopub.status.idle":"2024-07-16T20:58:42.989301Z","shell.execute_reply.started":"2024-07-16T20:58:42.948894Z","shell.execute_reply":"2024-07-16T20:58:42.988110Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"126ba35faf014de8b77dcd448ad5fa2d"}},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# Section 4: Embedding faces","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Video 8: Embedding Faces Vignette\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'tF0iYBAnyrI'), ('Bilibili', 'BV1NY411K7f6')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:42.990957Z","iopub.execute_input":"2024-07-16T20:58:42.991310Z","iopub.status.idle":"2024-07-16T20:58:43.055092Z","shell.execute_reply.started":"2024-07-16T20:58:42.991278Z","shell.execute_reply":"2024-07-16T20:58:43.054041Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6374d9ed665c4de0968924e88f075fa8"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Embedding_Faces_Vignette_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:43.056335Z","iopub.execute_input":"2024-07-16T20:58:43.056674Z","iopub.status.idle":"2024-07-16T20:58:43.098475Z","shell.execute_reply.started":"2024-07-16T20:58:43.056645Z","shell.execute_reply":"2024-07-16T20:58:43.096934Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a55a47aee54411a4f57a9c4d6ff201"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Video 9: Embedding Faces Set-up\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'JrzicfOxqP0'), ('Bilibili', 'BV1fv4y1M7eQ')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:43.099772Z","iopub.execute_input":"2024-07-16T20:58:43.100118Z","iopub.status.idle":"2024-07-16T20:58:43.173074Z","shell.execute_reply.started":"2024-07-16T20:58:43.100087Z","shell.execute_reply":"2024-07-16T20:58:43.171914Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2545c07d713146f58cc1c50ba1867cdf"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Embedding_Faces_SetUp_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:43.174594Z","iopub.execute_input":"2024-07-16T20:58:43.175077Z","iopub.status.idle":"2024-07-16T20:58:43.215794Z","shell.execute_reply.started":"2024-07-16T20:58:43.175036Z","shell.execute_reply":"2024-07-16T20:58:43.214289Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bb5b676e9424bfca28668f439af9bc4"}},"metadata":{}}]},{"cell_type":"markdown","source":"Konrad needs help recognizing faces. He wants to build a network that embeds photos of faces so that photos of the same person are nearby in the embedding space and photos of different people are far in the embedding space. We can't just use pixel space because the pixels will be very different between a photo of someone straight on vs. from their side!\n\nWe will use a neural network to go from the pixels of each image to an embedding space. Let's say you have a convolutional neural network with m units in the last layer. If you feed a face photo $i$ through the CNN, the activities of the units in the last layer form an $m$ dimensional vector $\\bar{y}_i$ - this is an embedding of that face photo in $m$ dimensional space.\n\nWe think we might be able to incorporate Euclidean distance to help us here. The Euclidean distance between two vectors is:\n\n\\begin{equation}\nd(\\bar{y}_i, \\bar{y}_j) = \\sqrt{\\sum_{c=1}^m(\\bar{y}_{i_c} - \\bar{y}_{j_c})^2}\n\\end{equation}\n\n<br>\n\n**Note:** a minor remark here, there is an indexing error in the video where it says $i$ instead of $j$.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"## Think! 3: Designing a cost function for face embedding\n\nGiven everything you know, how would you design a cost function for a neural network that Konrad is training so that he can get a helpful embedding of faces? Try to write out an equation!\n\nPlease discuss as a group. If you get stuck, you can uncover the hints below one at a time. Please spend some time discussing before uncovering the next hint, though! You are being real deep learning scientists now, and the answers won't be easy.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 1 </font></summary>\n\nHow do we want to deal with the same faces? Can we just build a cost function based on similar faces? What would happen?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 2 </font></summary>\n\nYou need to also include different faces. How do you want to deal with different faces?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for hint 3 </font></summary>\n\nSimilar faces should have low Euclidean distance between their embeddings. Different faces should have high Euclidean distance between their embeddings. Can we phrase this with 3 faces?","metadata":{"execution":{}}},{"cell_type":"markdown","source":"<details>\n<summary> <font color='green'>Click here for the solution </font></summary>\n\nWe want the same faces to have similar embeddings. Let's say we have one photo of Lyle $a$ and another photo of Lyle $p$. We want the embeddings of those photos to be very similar: we want the Euclidean distance between $\\bar{y}_a$ and $\\bar{y}_p$ (the activitys of the last layer of the CNN when photo $a$ and $p$ are fed through) to be small.\n\nSo one possible cost function is:\n\n\\begin{equation}\n\\text{Cost function} = d(\\bar{y}_a, \\bar{y}_p)\n\\end{equation}\n\nImagine if we just feed in pairs of the same face and minimize that though. There would be no motivation to ever have different embeddings, we would be only minimizing the distance between embeddings. If the CNN was smart, it would just have the same embedding for every single photo - then the cost function would equal 0!\n\nThis is clearly not what we want. We want to motivate the CNN to have similar embeddings only when the faces are the same. This means we need to also train it to maximize distance when the faces are different.\n\nWe could choose another two photos of different people and maximize that distance but then there's no relation to the embeddings we've already established of the two photos of Lyle.  Instead, we will add one more photo to the mix: a photo of Konrad $n$. We want the distance of this photo to be far from our original photos of Lyle $a$ and $p$.  So we want the distance between $a$ and $p$ to be small and the distance between $a$ and $n$ for example to be large:\n\n\\begin{equation}\n\\text{Cost function} = d(\\bar{y}_a, \\bar{y}_p) - d(\\bar{y}_a, \\bar{y}_n)\n\\end{equation}\n\nWe could compare $n$ to both $a$ and $p$:\n\\begin{equation}\n\\text{Cost function} = d(\\bar{y}_a, \\bar{y}_p) - d(\\bar{y}_a, \\bar{y}_n) - d(\\bar{y}_p, \\bar{y}_n)\n\\end{equation}\n\nBut then the cost function is a bit unbalanced, there are two dissimiliarty terms and they might dominate (so achieving the similarity is less important). So let's go with just including one dissimilarity term.\n\nThis is an established cost function - triplet loss! We chose the subscripts $a$, $p$, and $n$ for a reason: we have an anchor image, a positive image (the same person's face as the anchor) and a negative image (a different person's face as the anchor). We can then sum over N data points where each data point is a set of three images:\n\n\\begin{equation}\n\\text{Cost function} = \\sum_{i=1}^N [d(\\bar{y}_{a, i}, \\bar{y}_{p, i}) - d(\\bar{y}_{a, i}, \\bar{y}_{n, i})]\n\\end{equation}\n\nThere's one little addition in triplet loss. Instead of just using the above cost function, researchers add a constant $\\alpha$ and then make the cost function 0 if it becomes negative. Why do you think they do this?\n\n\\begin{equation}\n\\text{Cost function} = \\text{max} \\left( \\sum_{i=1}^N \\left[ d(\\bar{y}_{a, i}, \\bar{y}_{p, i}) - d(\\bar{y}_{a, i}, \\bar{y}_{n, i}) + \\alpha \\right], 0 \\right)\n\\end{equation}","metadata":{"execution":{}}},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Embedding_Faces_Discussion\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:43.217254Z","iopub.execute_input":"2024-07-16T20:58:43.217630Z","iopub.status.idle":"2024-07-16T20:58:43.260875Z","shell.execute_reply.started":"2024-07-16T20:58:43.217599Z","shell.execute_reply":"2024-07-16T20:58:43.259792Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ab03967f4f44b2971c6b03c1f8da1f"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Video 10: Embedding Faces Wrap-up\nfrom ipywidgets import widgets\nfrom IPython.display import YouTubeVideo\nfrom IPython.display import IFrame\nfrom IPython.display import display\n\n\nclass PlayVideo(IFrame):\n  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n    self.id = id\n    if source == 'Bilibili':\n      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n    elif source == 'Osf':\n      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n\n\ndef display_videos(video_ids, W=400, H=300, fs=1):\n  tab_contents = []\n  for i, video_id in enumerate(video_ids):\n    out = widgets.Output()\n    with out:\n      if video_ids[i][0] == 'Youtube':\n        video = YouTubeVideo(id=video_ids[i][1], width=W,\n                             height=H, fs=fs, rel=0)\n        print(f'Video available at https://youtube.com/watch?v={video.id}')\n      else:\n        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n                          height=H, fs=fs, autoplay=False)\n        if video_ids[i][0] == 'Bilibili':\n          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n        elif video_ids[i][0] == 'Osf':\n          print(f'Video available at https://osf.io/{video.id}')\n      display(video)\n    tab_contents.append(out)\n  return tab_contents\n\n\nvideo_ids = [('Youtube', 'mVk1W7x6Nps'), ('Bilibili', 'BV1nf4y1f7oL')]\ntab_contents = display_videos(video_ids, W=854, H=480)\ntabs = widgets.Tab()\ntabs.children = tab_contents\nfor i in range(len(tab_contents)):\n  tabs.set_title(i, video_ids[i][0])\ndisplay(tabs)","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:43.262306Z","iopub.execute_input":"2024-07-16T20:58:43.262697Z","iopub.status.idle":"2024-07-16T20:58:43.331023Z","shell.execute_reply.started":"2024-07-16T20:58:43.262664Z","shell.execute_reply":"2024-07-16T20:58:43.329937Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bebbf40b86ca4bebb37d5e86e48540b5"}},"metadata":{}}]},{"cell_type":"code","source":"# @title Submit your feedback\ncontent_review(f\"{feedback_prefix}_Embedding_Faces_WrapUp_Video\")","metadata":{"cellView":"form","execution":{"iopub.status.busy":"2024-07-16T20:58:43.332417Z","iopub.execute_input":"2024-07-16T20:58:43.332788Z","iopub.status.idle":"2024-07-16T20:58:43.373107Z","shell.execute_reply.started":"2024-07-16T20:58:43.332757Z","shell.execute_reply":"2024-07-16T20:58:43.371579Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d410b35366c64bc4971887854224c482"}},"metadata":{}}]},{"cell_type":"markdown","source":"Check out the papers mentioned in the above video:\n\n- [Large Scale Online Learning of Image Similarity Through Ranking](https://www.jmlr.org/papers/volume11/chechik10a/chechik10a.pdf)\n","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n# Summary\n\nToday we have seen a range of different cost functions. So we want to dwell a bit on what we want people to take away from these exercises. We have seen several cost functions:\n\n* Log Poisson likelihood for neurons\n* Uncertainty as a modeled entity\n* Face embeddings\n\nWhat we saw in all these cases is that these cost functions emerge from insights into the problem domain. We saw how one needs to, in a way, pull these insights out of the domain experts. And how, at the same time, the cost functions come from computational insights. Coming up with the proper cost functions requires listening to what domain experts say and probing the things they may mean but not say.","metadata":{"execution":{}}},{"cell_type":"markdown","source":"---\n# Daily survey\n\nDon't forget to complete your reflections and content check in the daily survey! Please be patient after logging in as there is\na small delay before you will be redirected to the survey.\n\n<a href=\"https://portal.neuromatchacademy.org/api/redirect/to/3b139c3a-b116-4963-82bf-aeb5a73246eb\"><img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\" alt=\"button link to survey\" style=\"width:410px\"></a>","metadata":{"execution":{}}}]}